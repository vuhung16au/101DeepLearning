% Chapter 8, Section 5

\section{Optimization Challenges \difficultyInline{intermediate}}
\label{sec:challenges}

\subsection{Intuition: Why Training Gets Stuck}

Deep networks combine nonlinearity and depth, creating landscapes with flat plateaus, narrow valleys, and saddle points. Noise (SGD), momentum, and schedules act like navigational aids to keep moving and avoid getting stuck.\index{optimization!challenges}

\subsection{Vanishing and Exploding Gradients}

In deep networks, gradients can become exponentially small or large. See \gls{vanishing-gradient} and \gls{exploding-gradient}.

\textbf{Vanishing gradients:}
\begin{itemize}
    \item Common with sigmoid/tanh activations
    \item Mitigated by ReLU, batch normalization, residual connections
\end{itemize}

\textbf{Exploding gradients:}
\begin{itemize}
    \item Common in RNNs
    \item Mitigated by gradient clipping, careful initialization
\end{itemize}

\textbf{Gradient clipping:}\index{gradient clipping}
\begin{equation}
\vect{g} \leftarrow \frac{\vect{g}}{\max(1, \|\vect{g}\| / \theta)}
\end{equation}

\subsection{Local Minima and Saddle Points}\index{saddle point}

In high dimensions, saddle points are more common than local minima.

Saddle points have:
\begin{itemize}
    \item Zero gradient
    \item Mixed curvature (positive and negative eigenvalues)
\end{itemize}

Momentum and noise help escape saddle points.

\subsubsection{Example: Critical Points in Two Dimensions}

Consider the function $f(x,y) = x^4 - 2x^2 + y^2$ to illustrate different types of critical points:

\textbf{Local minimum:} Bottom of a bowl - you can't go lower in any direction
\begin{itemize}
    \item At $(0,0)$: $f(0,0) = 0$ is a local minimum
    \item All nearby points have higher function values
    \item Gradient is zero: $\nabla f = (4x^3 - 4x, 2y) = (0,0)$
    \item Hessian has positive eigenvalues (concave up in all directions)
\end{itemize}

\textbf{Local maximum:} Top of a hill - you can't go higher in any direction
\begin{itemize}
    \item At $(0,0)$ for $f(x,y) = -x^4 + 2x^2 - y^2$: would be a local maximum
    \item All nearby points have lower function values
    \item Hessian has negative eigenvalues (concave down in all directions)
\end{itemize}

\textbf{Saddle point:} Mountain pass - you can go down in some directions, up in others
\begin{itemize}
    \item At $(1,0)$ and $(-1,0)$: $f(\pm 1,0) = -1$ are saddle points
    \item Gradient is zero: $\nabla f = (4x^3 - 4x, 2y) = (0,0)$
    \item Hessian has mixed eigenvalues (concave up in one direction, down in another)
    \item Like sitting on a horse saddle: you can slide down the sides but the saddle curves up in front/back
\end{itemize}

In high-dimensional optimization, saddle points are much more common than local minima, making them the primary challenge for gradient-based methods.

\subsection{Plateaus}\index{plateau}

Flat regions with small gradients slow convergence. Adaptive methods and learning rate schedules help navigate plateaus.

\subsection{Practical Optimization Strategy}

\textbf{Recommended approach:}
\begin{enumerate}
    \item Start with Adam \cite{Kingma2014} for rapid progress; tune $\alpha$ in $\{10^{-3},3\cdot10^{-4},10^{-4}\}$.
    \item Use cosine decay with warmup for transformer-like models; step decay for CNNs with SGD+momentum \cite{WebOptimizationDLBook,D2LChapterOptimization,He2016}.
    \item If validation accuracy saturates, consider switching from Adam to SGD+Nesterov with tuned $\alpha$ and $\beta$ to improve generalization.
    \item Apply gradient clipping in recurrent models and when training becomes unstable.\index{gradient clipping}
    \item Monitor training/validation loss, accuracy, and learning-rate schedule. Use early stopping when needed.\index{early stopping}
\end{enumerate}

Applications and heuristics:
\begin{itemize}
    \item Vision: SGD+momentum or Nesterov often yields state-of-the-art with careful schedules and augmentations \cite{He2016}.
    \item NLP/Transformers: Adam/AdamW with warmup+cosine is a strong default; clip global norm in seq2seq models.
    \item Reinforcement learning: Adam with small $\alpha$ stabilizes non-stationary objectives.
\end{itemize}

Common failure modes:
\begin{itemize}
    \item Divergence at start: reduce $\alpha$, add warmup, or increase \(\epsilon\) for Adam.
    \item Plateau: try larger batch with warmup, use cosine schedule, or add momentum.
    \item Overfitting: increase regularization (weight decay, dropout), add data augmentation.
\end{itemize}
