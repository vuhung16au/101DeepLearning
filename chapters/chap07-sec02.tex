% Chapter 7, Section 2

\section{Dataset Augmentation \difficultyInline{intermediate}}
\label{sec:data-augmentation}

\textbf{Data augmentation} artificially increases training set size by applying transformations that preserve labels.

\subsection{Intuition: Seeing the Same Thing in Many Ways}

Humans recognize an object despite different viewpoints, lighting, or small occlusions. Augmentation teaches models the same robustness by showing multiple, label-preserving variations of each example. This reduces overfitting by making spurious correlations less useful and forcing the model to focus on invariant structure.

\subsection{Image Augmentation}

Common transformations:
\begin{itemize}
    \item \textbf{Geometric:} rotation, translation, scaling, flipping, cropping
    
    These transformations change the spatial properties of images while preserving the semantic content. Rotation and translation help models become invariant to object orientation and position, while scaling and cropping teach robustness to different object sizes and partial views.
    
    \item \textbf{Color:} brightness, contrast, saturation adjustments
    
    These modifications simulate different lighting conditions and camera settings that occur in real-world scenarios. By varying these color properties, models learn to focus on structural features rather than specific color characteristics, improving generalization across different environments.
    
    \item \textbf{Noise:} Gaussian noise, blur
    
    Adding controlled noise and blur helps models become more robust to sensor imperfections and motion blur that occur in real images. This regularization technique prevents overfitting to pixel-perfect training data and improves performance on noisy real-world inputs.
    
    \item \textbf{Cutout/Erasing:} randomly mask regions
    
    This technique randomly removes rectangular regions from images, forcing the model to learn from partial information. It encourages the network to not rely on specific spatial locations and instead learn more distributed, robust feature representations.
    
    \item \textbf{Mixup:} blend pairs of images and labels
    
    Mixup creates new training examples by linearly interpolating between pairs of images and their corresponding labels. This technique encourages smoother decision boundaries and reduces overconfident predictions, leading to better calibration and generalization.
\end{itemize}

Example: horizontal flip
\begin{equation}
\vect{x}_{\text{aug}} = \text{flip}(\vect{x}), \quad y_{\text{aug}} = y
\end{equation}

\subsection{Text Augmentation}

For NLP:
\begin{itemize}
    \item Synonym replacement
    
    This technique replaces words with their synonyms while preserving the original meaning and label. It helps models become more robust to vocabulary variations and reduces overfitting to specific word choices, improving generalization to unseen text variations.
    
    \item Random insertion/deletion
    
    These operations randomly add or remove words from sentences, simulating natural language variations and typos. This augmentation helps models become more robust to noisy text inputs and teaches them to focus on important content rather than exact word sequences.
    
    \item Back-translation
    
    This method translates text to another language and then back to the original language, creating paraphrased versions with the same meaning. It generates diverse sentence structures while preserving semantic content, helping models learn more robust language representations.
    
    \item Paraphrasing
    
    This technique rewrites sentences using different wording while maintaining the same meaning and label. It exposes models to various ways of expressing the same concept, improving their ability to generalize to different writing styles and linguistic variations.
\end{itemize}

\subsection{Audio Augmentation}

For speech/audio:
\begin{itemize}
    \item Time stretching
    
    This technique changes the duration of audio signals without affecting pitch, simulating different speaking rates. It helps models become robust to variations in speech tempo while preserving the fundamental frequency characteristics and semantic content of the audio.
    
    \item Pitch shifting
    
    This augmentation modifies the fundamental frequency of audio while keeping the duration constant, simulating different voice characteristics. It helps models learn pitch-invariant features and improves generalization across speakers with different vocal ranges.
    
    \item Adding background noise
    
    This technique introduces various types of noise to simulate real-world acoustic environments. It helps models become robust to environmental factors like room acoustics, background conversations, and equipment noise, improving performance in noisy conditions.
    
    \item SpecAugment (masking frequency/time regions)
    
    This method randomly masks frequency bands or time segments in spectrograms, forcing models to learn from partial information. It encourages the network to develop more robust acoustic representations that don't rely on specific frequency or temporal patterns.
\end{itemize}

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
    % Original image placeholder
    \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
    \node at (1.5,1) {Original};
    % Rotated
    \begin{scope}[xshift=120]
        \draw[fill=bookpurple!10,rotate=10] (0,0) rectangle (3,2);
        \node at (1.5,1) {Rotate};
    \end{scope}
    % Flipped
    \begin{scope}[xshift=240]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \node at (1.5,1) {Flip};
    \end{scope}
    % Cropped
    \begin{scope}[yshift=-80]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \draw[bookred,thick] (0.5,0.5) rectangle (2.5,1.5);
        \node at (1.5,1) {Crop};
    \end{scope}
    % Color jitter
    \begin{scope}[xshift=120,yshift=-80]
        \shade[left color=bookpurple!10,right color=bookred!20] (0,0) rectangle (3,2);
        \node at (1.5,1) {Color};
    \end{scope}
    % Cutout
    \begin{scope}[xshift=240,yshift=-80]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \draw[fill=bookblack!60] (1,0.7) rectangle (2,1.3);
        \node at (1.5,1) {Cutout};
    \end{scope}
\end{tikzpicture}
\caption{Illustration of common image augmentations. Variants preserve labels while encouraging invariances.}
\label{fig:augmentation-examples}
\end{figure}

% Index entries
\index{data augmentation}
\index{augmentation!vision}
\index{augmentation!text}
\index{augmentation!audio}

