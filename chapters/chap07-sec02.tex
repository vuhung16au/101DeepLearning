% Chapter 7, Section 2

\section{Dataset Augmentation \difficultyInline{intermediate}}
\label{sec:data-augmentation}

\textbf{Data augmentation} artificially increases training set size by applying transformations that preserve labels.

\subsection{Intuition: Seeing the Same Thing in Many Ways}

Humans recognize an object despite different viewpoints, lighting, or small occlusions. Augmentation teaches models the same robustness by showing multiple, label-preserving variations of each example. This reduces overfitting by making spurious correlations less useful and forcing the model to focus on invariant structure.

\subsection{Image Augmentation}

Image augmentation employs various transformations to artificially expand the training dataset while preserving semantic content. Geometric transformations including rotation, translation, scaling, flipping, and cropping change the spatial properties of images while preserving the semantic content, where rotation and translation help models become invariant to object orientation and position, while scaling and cropping teach robustness to different object sizes and partial views. Color modifications such as brightness, contrast, and saturation adjustments simulate different lighting conditions and camera settings that occur in real-world scenarios, where by varying these color properties, models learn to focus on structural features rather than specific color characteristics, improving generalization across different environments. Noise augmentation including Gaussian noise and blur helps models become more robust to sensor imperfections and motion blur that occur in real images, where this regularization technique prevents overfitting to pixel-perfect training data and improves performance on noisy real-world inputs. Cutout and erasing techniques randomly remove rectangular regions from images, forcing the model to learn from partial information and encouraging the network to not rely on specific spatial locations, instead learning more distributed, robust feature representations. Mixup creates new training examples by linearly interpolating between pairs of images and their corresponding labels, encouraging smoother decision boundaries and reducing overconfident predictions, leading to better calibration and generalization.

Example: horizontal flip
\begin{equation}
\vect{x}_{\text{aug}} = \text{flip}(\vect{x}), \quad y_{\text{aug}} = y
\end{equation}

\subsection{Text Augmentation}

Text augmentation techniques for natural language processing include synonym replacement, which replaces words with their synonyms while preserving the original meaning and label, helping models become more robust to vocabulary variations and reducing overfitting to specific word choices, improving generalization to unseen text variations. Random insertion and deletion operations randomly add or remove words from sentences, simulating natural language variations and typos, where this augmentation helps models become more robust to noisy text inputs and teaches them to focus on important content rather than exact word sequences. Back-translation translates text to another language and then back to the original language, creating paraphrased versions with the same meaning, generating diverse sentence structures while preserving semantic content and helping models learn more robust language representations. Paraphrasing rewrites sentences using different wording while maintaining the same meaning and label, exposing models to various ways of expressing the same concept and improving their ability to generalize to different writing styles and linguistic variations.

\subsection{Audio Augmentation}

Audio augmentation techniques for speech and audio processing include time stretching, which changes the duration of audio signals without affecting pitch, simulating different speaking rates and helping models become robust to variations in speech tempo while preserving the fundamental frequency characteristics and semantic content of the audio. Pitch shifting modifies the fundamental frequency of audio while keeping the duration constant, simulating different voice characteristics and helping models learn pitch-invariant features while improving generalization across speakers with different vocal ranges. Adding background noise introduces various types of noise to simulate real-world acoustic environments, helping models become robust to environmental factors like room acoustics, background conversations, and equipment noise, improving performance in noisy conditions. SpecAugment randomly masks frequency bands or time segments in spectrograms, forcing models to learn from partial information and encouraging the network to develop more robust acoustic representations that don't rely on specific frequency or temporal patterns.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
    % Original image placeholder
    \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
    \node at (1.5,1) {Original};
    % Rotated
    \begin{scope}[xshift=120]
        \draw[fill=bookpurple!10,rotate=10] (0,0) rectangle (3,2);
        \node at (1.5,1) {Rotate};
    \end{scope}
    % Flipped
    \begin{scope}[xshift=240]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \node at (1.5,1) {Flip};
    \end{scope}
    % Cropped
    \begin{scope}[yshift=-80]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \draw[bookred,thick] (0.5,0.5) rectangle (2.5,1.5);
        \node at (1.5,1) {Crop};
    \end{scope}
    % Color jitter
    \begin{scope}[xshift=120,yshift=-80]
        \shade[left color=bookpurple!10,right color=bookred!20] (0,0) rectangle (3,2);
        \node at (1.5,1) {Color};
    \end{scope}
    % Cutout
    \begin{scope}[xshift=240,yshift=-80]
        \draw[fill=bookpurple!10] (0,0) rectangle (3,2);
        \draw[fill=bookblack!60] (1,0.7) rectangle (2,1.3);
        \node at (1.5,1) {Cutout};
    \end{scope}
\end{tikzpicture}
\caption{Illustration of common image augmentations. Variants preserve labels while encouraging invariances.}
\label{fig:augmentation-examples}
\end{figure}

% Index entries
\index{data augmentation}
\index{augmentation!vision}
\index{augmentation!text}
\index{augmentation!audio}

