% Chapter 7, Section 3

\section{Early Stopping \difficultyInline{intermediate}}
\label{sec:early-stopping}

\textbf{Early stopping} monitors validation performance and stops training when it begins to degrade.

\subsection{Intuition: Stop Before You Memorize}

Imagine studying for an exam. Initially, practice improves your understanding (training and validation improve). If you keep cramming the exact same questions, you start memorizing answers that don't help with new questions (training improves, validation worsens). Early stopping is the principle of stopping at the point of best validation performance to avoid memorization.

\subsection{Algorithm}

The early stopping algorithm works by training the model and evaluating it on the validation set periodically, tracking the best validation performance throughout training. If there is no improvement for $p$ epochs (patience), the training stops, and the algorithm returns the model with the best validation performance, ensuring that the network is saved at its optimal generalization point rather than continuing to overfit.

\begin{remark}[Early Stopping in Modern Frameworks]
Modern deep learning frameworks like Hugging Face Transformers, TensorFlow, and PyTorch provide built-in early stopping capabilities that can be configured manually or systematically. These frameworks offer options to monitor validation metrics, set patience parameters, save checkpoints automatically, and restore the best model, making early stopping implementation straightforward and robust across different model architectures and training scenarios.
\end{remark}

\begin{algorithm}
\caption{Early stopping meta-algorithm}
\label{alg:early-stopping}
\begin{algorithmic}
\Require $n \geq 1$ (number of steps between evaluations)
\Require $p \geq 1$ (patience: number of worsened validations before stopping)
\Require $\vect{\theta}_0$ (initial parameters)
\Ensure Best parameters $\vect{\theta}^*$ and best step $i^*$
\State $\vect{\theta} \gets \vect{\theta}_0$, $i \gets 0$, $j \gets 0$, $v \gets \infty$
\State $\vect{\theta}^* \gets \vect{\theta}$, $i^* \gets i$
\While{$j < p$}
    \State Update $\vect{\theta}$ by running the training algorithm for $n$ steps
    \State $i \gets i + n$
    \State $v' \gets \text{ValidationSetError}(\vect{\theta})$
    \If{$v' < v$}
        \State $j \gets 0$
        \State $\vect{\theta}^* \gets \vect{\theta}$, $i^* \gets i$, $v \gets v'$
    \Else
        \State $j \gets j + 1$
    \EndIf
\EndWhile
\State \Return $\vect{\theta}^*$, $i^*$
\end{algorithmic}
\end{algorithm}

\subsection{Benefits}

Early stopping is simple and effective, requiring only tracking validation performance and a patience parameter while being widely used in practice. It automatically determines training duration by finding a good stopping time without a pre-fixed epoch budget, often saving substantial compute resources. Early stopping provides implicit regularization by halting before convergence, which limits effective capacity by keeping weights smaller and preventing memorization, where in some regimes it mimics an L2 constraint under gradient descent. It is compatible with many settings, working with any loss function, architecture including MLPs, CNNs, and Transformers, and any optimizer. Early stopping reduces computational cost by stopping training as soon as overfitting begins, reducing energy and time requirements, while improving generalization stability by curbing validation variance late in training when overfitting spikes.

\subsection{Considerations}

Early stopping requires a reliable validation protocol with a proper validation set and evaluation cadence, where noisy metrics may trigger premature stops and should be addressed using smoothing or requiring monotone improvements. The patience parameter $p$ and evaluation interval $n$ interact with learning rate schedules, where too small $p$ can stop before a scheduled learning rate drop helps. Checkpointing is crucial, as you should always restore the best model rather than the last one, keeping track of the weights at the best validation step. With warmup or long plateaus, consider larger patience or metric smoothing to avoid premature stopping. For tasks with multiple metrics like accuracy and calibration, pick the primary metric or create a composite metric. In distributed training, ensure validation statistics are aggregated consistently across devices to avoid spurious decisions. Early stopping predates modern deep learning and was popular in classical neural nets and boosting as a strong regularizer, remaining a standard baseline technique.

\begin{example}
\textbf{Example (vision):} Train a ResNet on CIFAR-10 with validation accuracy checked each epoch; use patience $p=20$. Accuracy peaks at epoch 142; training halts at 162 without improvement, and the checkpoint from 142 is used for testing.
\end{example}

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[scale=0.85]
    % axes
    \draw[->] (0,0) -- (9,0) node[right] {Epochs};
    \draw[->] (0,0) -- (0,4.5) node[above] {Loss};
    % training loss curve
    \draw[draw=bookred, thick] plot[smooth] coordinates {(0.3,4) (1,3.2) (2,2.6) (3,2.2) (4,1.9) (5,1.7) (6,1.5) (7,1.4) (8,1.35)};
    % validation loss curve (U-shaped)
    \draw[draw=bookpurple, thick] plot[smooth] coordinates {(0.3,3.9) (1,3.1) (2,2.5) (3,2.15) (4,1.95) (5,1.92) (6,1.95) (7,2.05) (8,2.2)};
    % vertical line at best epoch
    \draw[dashed] (4,0) -- (4,4.5) node[above] {Best epoch};
    \node[text=bookpurple] at (6.9,2.3) {Validation};
    \node[text=bookred] at (7.3,1.35) {Training};
\end{tikzpicture}
\caption{Early stopping: validation loss minimum before training loss; best checkpoint saved and restored.}
\label{fig:early-stopping-curve}
\end{figure}

% Index entries
\index{early stopping}
\index{validation set}

