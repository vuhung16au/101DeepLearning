% Chapter 8, Section 2

\section{Momentum-Based Methods \difficultyInline{intermediate}}
\noindent One-liner: Momentum smooths gradients by accumulating an exponential moving average of past updates, accelerating descent along gentle directions while damping oscillations in steep ones.
\label{sec:momentum}

\subsection{Intuition: Rolling a Ball Down a Valley}

Plain SGD can wobble like a marble on a bumpy path. \textbf{Momentum} acts like mass: it carries velocity so you keep moving in consistently good directions and smooth out small bumps. Imagine a heavy ball rolling down a hillâ€”its mass (momentum) helps it maintain direction even when hitting small bumps, just like how momentum accumulates past gradients to maintain consistent movement in the loss landscape. The derivative of momentum with respect to time gives us the acceleration, but in optimization, we use the derivative of the loss with respect to parameters to determine the direction, while momentum provides the "inertia" to keep moving smoothly. \textbf{Nesterov acceleration} adds anticipation by peeking where the momentum will take you before correcting, often yielding crisper steps in curved valleys. Think of it like a skilled skier who looks ahead to anticipate the curve and adjusts their trajectory before reaching it, rather than just following their current momentum and then correcting afterward. This "look-ahead" approach helps the optimizer make more informed decisions by evaluating the gradient at the anticipated future position, leading to smoother and more efficient convergence.\index{momentum}\index{Nesterov}

Historical note: Momentum has deep roots in convex optimization and was popularized in early neural network training; Nesterov's variant provided stronger theoretical guarantees in convex settings and inspired practical variants in deep learning \cite{Polyak1964,Nesterov1983,GoodfellowEtAl2016,Bishop2006}.

\subsection{Momentum}

Momentum accumulates gradients over time to maintain velocity in consistently good directions, effectively smoothing out oscillations and accelerating convergence in relevant directions. The mathematical formulation builds an exponentially weighted moving average of past gradients, creating a low-pass filter that suppresses high-frequency noise while preserving important directional information.

The update equations accumulate velocity and apply it to parameter updates:
\begin{align}
\vect{v}_t &= \beta \vect{v}_{t-1} - \alpha \nabla_{\vect{\theta}} L(\vect{\theta}_t) \\
\vect{\theta}_{t+1} &= \vect{\theta}_t + \vect{v}_t
\end{align}

where $\beta \in [0, 1)$ is the momentum coefficient, typically set to 0.9, controlling how much past gradient information to retain.\index{optimization!momentum}

This approach accelerates convergence in relevant directions by maintaining velocity along consistent gradient directions while dampening oscillations that occur when gradients change rapidly. The momentum mechanism helps escape local minima and saddle points by providing sufficient inertia to overcome small gradient magnitudes that might otherwise trap the optimizer.

The mathematical interpretation reveals that momentum implements an exponentially weighted moving average of past gradients, effectively creating a low-pass filter that suppresses high-frequency noise. In anisotropic valleys with different curvatures along different dimensions, momentum allows larger effective steps along shallow curvature directions while reducing the characteristic zig-zag pattern across sharp directions. The choice of hyperparameters requires careful tuning, with \(\beta\in[0.8,0.99]\) providing different levels of smoothing and memory, while the learning rate \(\alpha\) must be balanced to prevent divergence.\cite{Polyak1964,WebOptimizationDLBook,D2LChapterOptimization}

Example (ravine function): For \(L(\theta_1,\theta_2)=100\theta_1^2+\theta_2^2\), momentum reduces oscillations in the steep \(\theta_1\) direction and speeds travel along the gentle \(\theta_2\) direction.

\subsection{Nesterov Accelerated Gradient (NAG)}\index{optimization!Nesterov}

Nesterov Accelerated Gradient implements a "look-ahead" version of momentum that evaluates the gradient at an anticipated future position, providing more informed updates that often yield better convergence properties. This anticipatory approach allows the optimizer to correct its course earlier, reducing overshoot in curved valleys and improving convergence rates.

The mathematical formulation computes gradients at the look-ahead position:
\begin{align}
\vect{v}_t &= \beta \vect{v}_{t-1} - \alpha \nabla_{\vect{\theta}} L(\vect{\theta}_t + \beta \vect{v}_{t-1}) \\
\vect{\theta}_{t+1} &= \vect{\theta}_t + \vect{v}_t
\end{align}

By computing the gradient at the look-ahead point \(\theta_t+\beta v_{t-1}\), NAG corrects the course earlier than standard momentum, which reduces overshoot in curved valleys and can significantly improve convergence rates, particularly in convex optimization settings. This anticipatory mechanism allows the optimizer to make more informed decisions by evaluating the gradient at where the momentum will take it, rather than just following the current momentum and correcting afterward.\cite{Nesterov1983,WebOptimizationDLBook,GoodfellowEtAl2016}

\begin{remark}[Nesterov Accelerated Gradient Practice Notes]
Common defaults: \(\beta=0.9\), initial \(\alpha\in[10^{-3},10^{-1}]\) depending on scale. Widely used with SGD in large-scale vision models \cite{He2016}. Start with \(\beta=0.9\) and tune \(\alpha\) based on your loss scale; for well-normalized networks, \(\alpha=0.01\) often works well. NAG typically requires fewer iterations than standard momentum to converge, making it particularly valuable for expensive training runs. The look-ahead gradient computation adds minimal computational overhead (one extra gradient evaluation per step) while often providing significant convergence improvements. Consider using NAG when training deep networks with many parameters, as the anticipation effect helps navigate complex loss landscapes more efficiently than standard momentum.
\end{remark}

