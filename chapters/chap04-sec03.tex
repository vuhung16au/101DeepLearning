% Chapter 4, Section 3: Constrained Optimization

\section{Constrained Optimization \difficultyInline{beginner}}
\label{sec:constrained-optimization}

Constrained optimization extends traditional optimization by incorporating additional requirements or limitations that must be satisfied while finding optimal solutions, providing essential tools for implementing regularization, fairness constraints, and other practical considerations in deep learning applications.

\subsection{Intuition: Optimization with Rules}

Imagine you're trying to find the best location for a new store, but you have constraints such as being within 10 km of the city centre, having parking for at least 50 cars, and a budget that cannot exceed \$1 million. You can't just pick any location - you must follow these rules while still optimizing your objective like maximizing customer traffic. In deep learning, we often have similar constraints including weight constraints to keep weights small and prevent overfitting, probability constraints where outputs must sum to 1 like in softmax functions, and fairness constraints where the model must treat different groups equally. Many problems require optimizing a function subject to constraints, making constrained optimization an essential tool for practical machine learning applications.

\subsection{Lagrange Multipliers}

For equality constraint $g(\vect{x}) = 0$, the \textbf{Lagrangian} is:

\begin{equation}
\mathcal{L}(\vect{x}, \lambda) = f(\vect{x}) + \lambda g(\vect{x})
\end{equation}

At the optimum, both:
\begin{equation}
\nabla_{\vect{x}} \mathcal{L} = \boldsymbol{0} \quad \text{and} \quad \frac{\partial \mathcal{L}}{\partial \lambda} = 0
\end{equation}

\subsection{Inequality Constraints}

For inequality constraint $g(\vect{x}) \leq 0$, we use the \textbf{Karush-Kuhn-Tucker (KKT)} conditions:

\begin{align}
\nabla_{\vect{x}} \mathcal{L} &= \boldsymbol{0} \\
\lambda &\geq 0 \\
\lambda g(\vect{x}) &= 0 \quad \text{(complementary slackness)} \\
g(\vect{x}) &\leq 0
\end{align}

\subsection{Projected Gradient Descent}

For constraints defining a set $\mathcal{C}$, \textbf{projected gradient descent} applies:

\begin{equation}
\vect{x}_{t+1} = \text{Proj}_{\mathcal{C}}\left(\vect{x}_t - \alpha \nabla f(\vect{x}_t)\right)
\end{equation}

where $\text{Proj}_{\mathcal{C}}$ projects onto the feasible set.

\subsection{Applications in Deep Learning}

Constrained optimization appears in several important applications in deep learning, including weight constraints such as unit norm constraints that help prevent overfitting and improve generalization, projection to valid probability distributions that ensures model outputs are mathematically valid, adversarial training with bounded perturbations that creates robust models by training against carefully crafted adversarial examples, and fairness constraints that ensure models treat different groups equally and avoid discriminatory behavior.
