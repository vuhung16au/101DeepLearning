% Chapter 20, Section 3

\section{Normalizing Flows \difficultyInline{advanced}}
\label{sec:normalizing-flows}

\subsection{Key Idea}

Transform simple distribution (e.g., Gaussian) through invertible mappings:
\begin{equation}
\vect{x} = f_{\theta}(\vect{z}), \quad \vect{z} \sim p_z(\vect{z})
\end{equation}

\subsection{Change of Variables}

Density transforms as:
\begin{equation}
p_x(\vect{x}) = p_z(f^{-1}(\vect{x})) \left|\det \frac{\partial f^{-1}}{\partial \vect{x}}\right|
\end{equation}

or equivalently:
\begin{equation}
\log p_x(\vect{x}) = \log p_z(\vect{z}) - \log\left|\det \frac{\partial f}{\partial \vect{z}}\right|
\end{equation}

\subsection{Requirements}

Function $f$ must be:
\begin{itemize}
    \item Invertible
    \item Have tractable Jacobian determinant
\end{itemize}

\subsection{Flow Architectures}

\textbf{Coupling layers:} Split dimensions and transform half conditioned on other half

\textbf{Autoregressive flows:} Each dimension depends on previous ones

\textbf{Continuous normalizing flows:} Use neural ODEs

\subsection{Advantages}

\begin{itemize}
    \item Exact likelihood computation
    \item Exact sampling
    \item Stable training (no adversarial dynamics)
\end{itemize}

% \subsection{Visual aids}
% \addcontentsline{toc}{subsubsection}{Visual aids (flows)}

% \begin{figure}[h]
%   \centering
%   \begin{tikzpicture}
%     \begin{axis}[
%       width=0.48\textwidth,height=0.36\textwidth,
%       xlabel={$z_1$}, ylabel={$z_2$}, grid=both]
%       \addplot+[only marks,mark=*,mark size=0.8pt,bookpurple!60] coordinates{(-1,-1) (-1,1) (1,-1) (1,1)};
%     \end{axis}
%   \end{tikzpicture}
%   \caption{Toy latent samples before/after flow transformation (illustrative).}
%   \label{fig:flow-toy}
% \end{figure}

% \subsection{Notes and references}

% See \textcite{GoodfellowEtAl2016,Prince2023} for flow-based modeling and practical design choices.

