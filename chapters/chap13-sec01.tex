% Chapter 13, Section 1

\section{Probabilistic PCA \difficultyInline{intermediate}}
\label{sec:prob-pca}

\subsection{Principal Component Analysis Review}

PCA finds orthogonal directions of maximum variance:
\begin{equation}
\vect{z} = \mat{W}^\top (\vect{x} - \boldsymbol{\mu})
\end{equation}

where $\mat{W}$ contains principal components (eigenvectors of covariance matrix).

\subsection{Probabilistic Formulation}

Model observations as:
\begin{align}
\vect{z} &\sim \mathcal{N}(\boldsymbol{0}, \mat{I}) \\
\vect{x} | \vect{z} &\sim \mathcal{N}(\mat{W}\vect{z} + \boldsymbol{\mu}, \sigma^2 \mat{I})
\end{align}

Marginalizing over $\vect{z}$:
\begin{equation}
\vect{x} \sim \mathcal{N}(\boldsymbol{\mu}, \mat{W}\mat{W}^\top + \sigma^2 \mat{I})
\end{equation}

\subsection{Learning}

Maximize likelihood using EM algorithm:
\begin{itemize}
    \item \textbf{E-step:} Compute $p(\vect{z}|\vect{x})$
    \item \textbf{M-step:} Update $\mat{W}$, $\boldsymbol{\mu}$, $\sigma^2$
\end{itemize}

As $\sigma^2 \to 0$, recovers standard PCA.

% \subsection{Visual aids}
% \addcontentsline{toc}{subsubsection}{Visual aids (PPCA)}

% \begin{figure}[h]
%   \centering
%   \begin{tikzpicture}
%     \begin{axis}[
%       width=0.48\textwidth,height=0.36\textwidth,
%       xlabel={$x_1$}, ylabel={$x_2$}, grid=both]
%       % data cloud
%       \addplot+[only marks,mark=*,mark size=0.8pt,bookpurple!60] coordinates{(-1.2,-0.9) (-0.8,-0.7) (-0.2,-0.3) (0.2,0.1) (0.6,0.4) (1.0,0.8)};
%       % principal axis
%       \addplot[bookred,very thick,domain=-1.5:1.5]{0.8*x};
%     \end{axis}
%   \end{tikzpicture}
%   \caption{PCA principal axis capturing maximum variance.}
%   \label{fig:ppca-axis}
% \end{figure}

\subsection{Historical context and references}

The probabilistic formulation connects PCA with latent variable models and enables principled handling of noise and missing data \textcite{Bishop2006,GoodfellowEtAl2016}.
