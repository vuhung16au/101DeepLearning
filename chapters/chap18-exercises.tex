% Exercises (Exercises) for Chapter 18

\section*{Exercises}
\addcontentsline{toc}{section}{Exercises}

\subsection*{Easy}

\begin{exercisebox}[easy]
\begin{problem}[MDP Definition]
Define the components of a Markov Decision Process.
\end{problem}
\begin{hintbox}
States, actions, rewards, transition dynamics, discount factor.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[easy]
\begin{problem}[Value Function]
Explain the difference between $V(s)$ and $Q(s,a)$.
\end{problem}
\begin{hintbox}
State value vs. action-value.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[easy]
\begin{problem}[Policy Types]
Contrast deterministic and stochastic policies.
\end{problem}
\begin{hintbox}
Mapping vs. distribution over actions.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[easy]
\begin{problem}[Exploration vs. Exploitation]
Give two exploration strategies in RL.
\end{problem}
\begin{hintbox}
$\epsilon$-greedy; UCB; entropy regularisation.
\end{hintbox}
\end{exercisebox}


\subsection*{Medium}

\begin{exercisebox}[medium]
\begin{problem}[Bellman Equation]
Derive the Bellman equation for $Q(s,a)$.
\end{problem}
\begin{hintbox}
Recursive relationship with successor states.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[medium]
\begin{problem}[Policy Gradient]
Explain why policy gradient methods are useful for continuous action spaces.
\end{problem}
\begin{hintbox}
Direct parameterisation; differentiability.
\end{hintbox}
\end{exercisebox}


\subsection*{Hard}

\begin{exercisebox}[hard]
\begin{problem}[Actor-Critic Derivation]
Derive the advantage actor-critic update rule.
\end{problem}
\begin{hintbox}
Baseline subtraction; variance reduction.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Off-Policy Correction]
Analyse importance sampling for off-policy learning and its variance.
\end{problem}
\begin{hintbox}
Likelihood ratio; distribution mismatch.
\end{hintbox}
\end{exercisebox}



\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 1]
Explain a key concept from this chapter and its practical applications.
\end{problem}
\begin{hintbox}
Consider the theoretical foundations and real-world implications.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 2]
Analyse the relationship between different techniques covered in this chapter.
\end{problem}
\begin{hintbox}
Look for connections and trade-offs between methods.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 3]
Design an experiment to test a hypothesis related to this chapter's content.
\end{problem}
\begin{hintbox}
Consider experimental design, metrics, and potential confounding factors.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 4]
Compare different approaches to solving a problem from this chapter.
\end{problem}
\begin{hintbox}
Consider computational complexity, accuracy, and practical considerations.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 5]
Derive a mathematical relationship or prove a theorem from this chapter.
\end{problem}
\begin{hintbox}
Start with the definitions and work through the logical steps.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 6]
Implement a practical solution to a problem discussed in this chapter.
\end{problem}
\begin{hintbox}
Consider the implementation details and potential challenges.
\end{hintbox}
\end{exercisebox}


\begin{exercisebox}[hard]
\begin{problem}[Advanced Topic 7]
Evaluate the limitations and potential improvements of techniques from this chapter.
\end{problem}
\begin{hintbox}
Consider both theoretical limitations and practical constraints.
\end{hintbox}
\end{exercisebox}

