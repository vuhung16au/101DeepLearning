% Problems (Exercises) for Chapter 11

\section*{Problems}
\addcontentsline{toc}{section}{Problems}

\subsection*{Easy}

\begin{problem}[Define Success Metrics]
You are building a classifier for defect detection. Propose suitable metrics beyond accuracy and justify validation splits.

\textbf{Hint:} Consider precision/recall, AUROC vs. AUPRC under class imbalance, and stratified splits.
\end{problem}

\begin{problem}[Sanity Checks]
List three quick sanity checks to run before large-scale training and explain expected outcomes.

\textbf{Hint:} Overfit a tiny subset; randomise labels; train with shuffled pixels.
\end{problem}

\begin{problem}[Baseline First]
Explain why a strong non-deep baseline can accelerate iteration on a deep model.

\textbf{Hint:} Separates data/metric issues from model capacity; provides performance floor.
\end{problem}

\begin{problem}[Data Leakage]
Define data leakage and give two concrete examples.

\textbf{Hint:} Temporal leakage; using normalised stats computed on the full dataset.
\end{problem}

\subsection*{Medium}

\begin{problem}[Hyperparameter Search Budget]
Given budget for 30 runs, propose an allocation between exploration (random search) and exploitation (local search). Defend your choice.

\textbf{Hint:} Start broad (e.g., 20 random), then refine top configurations (e.g., 10 local).
\end{problem}

\begin{problem}[Early Stopping vs. Schedules]
Compare early stopping with cosine decay schedules under limited training budget.

\textbf{Hint:} Consider variance, bias, and checkpoint selection.
\end{problem}

\subsection*{Hard}

\begin{problem}[Confidence Intervals]
Derive a 95\% Wilson interval for a classifier with $n$ samples and accuracy $\hat{p}$.

\textbf{Hint:} Use $\frac{\hat{p}+z^2/(2n) \pm z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}+\frac{z^2}{4n^2}}}{1+z^2/n}$ with $z\approx1.96$.
\end{problem}

\begin{problem}[Causal Confounding]
Your model uses a spurious feature. Propose an experimental protocol to detect and mitigate it.

\textbf{Hint:} Counterfactual augmentation, environment splitting, invariant risk minimisation.
\end{problem}


